{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea50a15",
   "metadata": {},
   "source": [
    "# Amazon Review Topic Exploration\n",
    "\n",
    "Goal:\n",
    "- Discover emotional and product-attribute topics\n",
    "- Unsupervised: Sentence embeddings ‚Üí HDBSCAN ‚Üí UMAP ‚Üí Cluster reading\n",
    "\n",
    "Dataset:\n",
    "- ~20k Amazon reviews\n",
    "- We will start with a 3k subset for fast iteration\n",
    "\n",
    "Workflow at a high level:\n",
    "1. 20k reviews\n",
    "2. Sentence embeddings (semantic meaning)\n",
    "3. HDBSCAN (density-based clustering, auto #clusters)\n",
    "4. UMAP (2D visualization)\n",
    "5. Read + label clusters (human-in-the-loop)\n",
    "\n",
    "Workflow at a detail level:\n",
    "1. Data Loading & Sampling\n",
    "2. Text Cleaning\n",
    "3. Embeddings (SentenceTransformer)\n",
    "4. Dimensionality Reduction (UMAP)\n",
    "5. Clustering (HDBSCAN)\n",
    "6. Cluster Inspection & Manual Labeling\n",
    "7. Auto-Labeling Unknown Clusters   üëà YOU ARE HERE\n",
    "8. Final Cluster Labels\n",
    "9. Visualization\n",
    "10. Export Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac79a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 ‚Äî Imports\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP & embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Clustering & dimensionality reduction\n",
    "import umap\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_cluster_examples\n",
    "\n",
    "def show_cluster_examples(cluster_id, n=10):\n",
    "    examples = (\n",
    "        df_work[df_work[\"cluster\"] == cluster_id]\n",
    "        .sample(min(n, (df_work[\"cluster\"] == cluster_id).sum()), random_state=42)\n",
    "    )\n",
    "\n",
    "    for i, row in examples.iterrows():\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        rating = row[\"rating\"] if \"rating\" in row else \"NA\"\n",
    "        verified = row[\"verified_purchase\"] if \"verified_purchase\" in row else \"NA\"\n",
    "\n",
    "        print(f\"Rating: {rating} | Verified: {verified}\")\n",
    "        print(row[\"doc\"][:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a8e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label clusters efficiently\n",
    "\n",
    "\n",
    "def top_terms(cluster_id, n=10):\n",
    "    texts = df_work[df_work[\"cluster\"] == cluster_id][\"doc\"]\n",
    "\n",
    "    if len(texts) == 0:\n",
    "        return []\n",
    "\n",
    "    tfidf = TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_features=1000,\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "\n",
    "    X = tfidf.fit_transform(texts)\n",
    "    scores = X.mean(axis=0).A1\n",
    "    terms = tfidf.get_feature_names_out()\n",
    "\n",
    "    top = sorted(\n",
    "        zip(terms, scores),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:n]\n",
    "\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label cluster\n",
    "\n",
    "def label_cluster(cluster_id, n_examples=10, n_terms=8):\n",
    "    print(f\"\\n=== Cluster {cluster_id} ===\\n\")\n",
    "    show_cluster_examples(cluster_id, n_examples)\n",
    "    print(\"\\nTop terms:\")\n",
    "    for term, score in top_terms(cluster_id, n_terms):\n",
    "        print(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d39757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 ‚Äî Load full data\n",
    "df = pd.read_csv(\"../data/reviews.csv\")\n",
    "print(\"Full dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2cd689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working set size: 3000\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 ‚Äî Create working subset (~3k) stratified by rating\n",
    "df_work = (\n",
    "    df.dropna(subset=[\"text\"])  # remove rows with missing text\n",
    "      .groupby(\"rating\", group_keys=False)\n",
    "      .apply(\n",
    "          lambda x: x.sample(n=min(len(x), 600), random_state=42),\n",
    "          include_groups=False  # avoids future warning\n",
    "      )\n",
    ")\n",
    "\n",
    "print(\"Working set size:\", len(df_work))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 ‚Äî Minimal cleaning & create 'doc' column\n",
    "\n",
    "# Ensure text is string\n",
    "df_work[\"text\"] = df_work[\"text\"].astype(str)\n",
    "\n",
    "# Combine title + text for better semantic embeddings\n",
    "df_work[\"doc\"] = df_work[\"title\"].fillna(\"\") + \". \" + df_work[\"text\"]\n",
    "\n",
    "# Quick sanity check\n",
    "df_work[[\"title\", \"text\", \"doc\"]].head(3)\n",
    "#display(df_work.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7542a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 ‚Äî Optional sanity check\n",
    "\n",
    "# Make sure 'doc' column exists\n",
    "assert \"doc\" in df_work.columns, \"'doc' column is missing ‚Äî run cleaning cell first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e473e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 ‚Äî Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64329f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 8 ‚Äî Generate embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embeddings = \u001b[43mmodel\u001b[49m.encode(\n\u001b[32m      4\u001b[39m     df_work[\u001b[33m\"\u001b[39m\u001b[33mdoc\u001b[39m\u001b[33m\"\u001b[39m].tolist(),\n\u001b[32m      5\u001b[39m     batch_size=\u001b[32m64\u001b[39m,\n\u001b[32m      6\u001b[39m     show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEmbeddings shape:\u001b[39m\u001b[33m\"\u001b[39m, embeddings.shape)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Convert to a DataFrame for easy saving\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 8 ‚Äî Generate embeddings\n",
    "\n",
    "embeddings = model.encode(\n",
    "    df_work[\"doc\"].tolist(),\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "# Convert to a DataFrame for easy saving\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df['user_id'] = df_work['user_id'].values  # keep an ID to match reviews\n",
    "\n",
    "# Save Embeddings to NPZ (compressed, faster to load)\n",
    "np.savez_compressed(\"amazon_embeddings_3k.npz\", embeddings=embeddings, user_id=df_work['user_id'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5751292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucy\\OneDrive\\Documents\\GitHub\\amazon_topic_analysis\\venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP-reduced shape: (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 ‚Äî UMAP (for clustering, 5D)\n",
    "umap_reducer = umap.UMAP(\n",
    "    n_neighbors=20,\n",
    "    n_components=5,\n",
    "    min_dist=0.0,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "embeddings_umap = umap_reducer.fit_transform(embeddings)\n",
    "\n",
    "print(\"UMAP-reduced shape:\", embeddings_umap.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70761d1e",
   "metadata": {},
   "source": [
    "Why this cell exists\n",
    "\n",
    "HDBSCAN works much better in reduced space\n",
    "\n",
    "5 dimensions preserves topic structure while removing noise\n",
    "\n",
    "This is not for visualization yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19acfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 ‚Äî HDBSCAN clustering\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=15,\n",
    "    min_samples=5,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\"\n",
    ")\n",
    "\n",
    "clusters = clusterer.fit_predict(embeddings_umap)\n",
    "df_work[\"cluster\"] = clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913b99e",
   "metadata": {},
   "source": [
    "Why these parameters\n",
    "\n",
    "min_cluster_size=30: stable, interpretable topics\n",
    "\n",
    "min_samples=10: moderate noise tolerance\n",
    "\n",
    "-1 cluster = noise (expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc8a938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "-1     918\n",
       " 24    215\n",
       " 26    155\n",
       " 2      86\n",
       " 5      76\n",
       " 23     75\n",
       " 36     73\n",
       " 7      68\n",
       " 29     58\n",
       " 45     56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 11 ‚Äî Cluster size overview\n",
    "\n",
    "df_work[\"cluster\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3ba28",
   "metadata": {},
   "source": [
    "What you‚Äôre looking for:\n",
    "\n",
    "Several clusters with dozens to hundreds of reviews\n",
    "\n",
    "Some -1 noise (10‚Äì30% is normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cluster_examples(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc3fec",
   "metadata": {},
   "source": [
    "Final Model Configuration (Frozen)\n",
    "\n",
    "Embedding: all-MiniLM-L6-v2\n",
    "UMAP:\n",
    "  n_neighbors=20\n",
    "  n_components=5\n",
    "  min_dist=0.0\n",
    "  metric=cosine\n",
    "\n",
    "HDBSCAN:\n",
    "  min_cluster_size=15\n",
    "  min_samples=5\n",
    "  metric=euclidean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87714ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cluster(46)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c071828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to amazon_review_cluster_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Summary saved to amazon_review_cluster_summary.csv\n",
    "# # summary_utils.py (can go in src/)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_top_terms(texts, n_terms=10):\n",
    "    \"\"\"Return top TF-IDF terms from a list of texts.\"\"\"\n",
    "    if len(texts) == 0:\n",
    "        return []\n",
    "    \n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\", max_features=1000, ngram_range=(1,2))\n",
    "    X = tfidf.fit_transform(texts)\n",
    "    scores = X.mean(axis=0).A1\n",
    "    terms = tfidf.get_feature_names_out()\n",
    "    top = sorted(zip(terms, scores), key=lambda x: x[1], reverse=True)[:n_terms]\n",
    "    return [term for term, score in top]\n",
    "\n",
    "def generate_cluster_summary(df, cluster_labels, n_terms=10, n_examples=3):\n",
    "    \"\"\"\n",
    "    Generate a summary table for clusters.\n",
    "    \n",
    "    df: pandas DataFrame with at least ['cluster', 'doc', 'verified_purchase']\n",
    "    cluster_labels: dict {cluster_id: human_label}\n",
    "    n_terms: number of top TF-IDF terms to extract\n",
    "    n_examples: number of review examples per cluster\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for cluster_id in sorted(df[\"cluster\"].unique()):\n",
    "        cluster_df = df[df[\"cluster\"] == cluster_id]\n",
    "        if cluster_df.empty:\n",
    "            continue\n",
    "\n",
    "        n_reviews = len(cluster_df)\n",
    "        verified_ratio = cluster_df[\"verified_purchase\"].mean() if \"verified_purchase\" in cluster_df.columns else None\n",
    "        label = cluster_labels.get(cluster_id, \"Unknown\")\n",
    "        terms = get_top_terms(cluster_df[\"doc\"], n_terms)\n",
    "        examples = cluster_df[\"doc\"].head(n_examples).tolist()\n",
    "\n",
    "        summary_data.append({\n",
    "            \"Cluster ID\": cluster_id,\n",
    "            \"Label\": label,\n",
    "            \"Top Terms\": \", \".join(terms),\n",
    "            \"Num Reviews\": n_reviews,\n",
    "            \"Verified Ratio\": round(verified_ratio, 2) if verified_ratio is not None else \"NA\",\n",
    "            \"Examples\": \"\\n---\\n\".join(examples)\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df\n",
    "\n",
    "def save_summary(df_summary, filepath=\"cluster_summary.csv\"):\n",
    "    \"\"\"Save the cluster summary DataFrame to CSV.\"\"\"\n",
    "    df_summary.to_csv(filepath, index=False)\n",
    "    print(f\"Summary saved to {filepath}\")\n",
    "\n",
    "\n",
    "\n",
    "# Define your cluster labels\n",
    "cluster_labels = {\n",
    "    2: \"Fit / Authenticity / Defects\",\n",
    "    5: \"Socks / Fit & Quality\",\n",
    "    7: \"Clothing / Fit & Quality\",\n",
    "    23: \"Shoes / Durability & Quality Issues\",\n",
    "    24: \"Positive / Satisfaction / Quality\",\n",
    "    26: \"Work / Durability / Fit\",\n",
    "    29: \"Shoes / Comfort & Satisfaction\",\n",
    "    36: \"Shoes / Fit & Width Issues\",\n",
    "    45: \"Socks / Fit & Comfort\",\n",
    "}\n",
    "\n",
    "# Generate the summary\n",
    "summary_df = generate_cluster_summary(df_work, cluster_labels)\n",
    "\n",
    "# Display in notebook\n",
    "summary_df\n",
    "\n",
    "# Save to CSV\n",
    "save_summary(summary_df, \"amazon_review_cluster_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a107a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code does NOT redo clustering.\n",
    "# üëâ It only turns clusters into a 2D picture so humans can understand them.\n",
    "\n",
    "#‚ÄúUMAP maps high-dimensional embeddings into a new 2-D coordinate system.\n",
    "#The two dimensions are learned by the algorithm and only represent relative similarity, not interpretable features.‚Äù\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Imports\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Sanity checks (optional but recommended)\n",
    "# -----------------------------\n",
    "print (\"\\nLoading df_work -----------------------\")\n",
    "display(df_work.head(3))\n",
    "\n",
    "required_cols = {\"text\", \"cluster\"}\n",
    "missing = required_cols - set(df_work.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"df_work is missing columns: {missing}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Compute embeddings from review text\n",
    "# -----------------------------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    df_work[\"text\"].tolist(),\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Run UMAP\n",
    "# -----------------------------\n",
    "reducer = umap.UMAP(\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1\n",
    ")\n",
    "\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "df_work[\"umap_x\"] = umap_embeddings[:, 0]\n",
    "df_work[\"umap_y\"] = umap_embeddings[:, 1]\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ Map human-readable cluster labels\n",
    "# -----------------------------\n",
    "cluster_labels = {\n",
    "    2: \"Fit / Authenticity / Defects\",\n",
    "    5: \"Socks / Fit & Quality\",\n",
    "    7: \"Clothing / Fit & Quality\",\n",
    "    23: \"Shoes / Durability & Quality\",\n",
    "    24: \"Positive / Satisfaction / Quality\",\n",
    "    26: \"Work / Durability / Fit\",\n",
    "    29: \"Shoes / Comfort & Satisfaction\",\n",
    "    36: \"Shoes / Fit & Width Issues\",\n",
    "    45: \"Socks / Fit & Comfort\"\n",
    "}\n",
    "\n",
    "df_work[\"label\"] = (\n",
    "    df_work[\"cluster\"]\n",
    "      .map(cluster_labels)\n",
    "      .fillna(\"Unknown\")\n",
    ")\n",
    "\n",
    " \n",
    "print (\"\\nAfter adding the label to df_work -----------------------\")\n",
    "display(df_work.head(3))\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ Plot clusters (human-readable)\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.scatterplot(\n",
    "    data=df_work,\n",
    "    x=\"umap_x\",\n",
    "    y=\"umap_y\",\n",
    "    hue=\"label\",\n",
    "    palette=\"tab20\",\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    legend=\"full\"\n",
    ")\n",
    "\n",
    "plt.title(\"UMAP Visualization of Amazon Review Clusters\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db15590",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Auto-label Remaining Clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns are currently in the df_work\n",
    "df_work.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19f00ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, [-1, 9, 3, 37, 50, 51, 12, 4, 48, 33])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1 ‚Äî Identify clusters that still need labels\n",
    "unknown_clusters = (\n",
    "    df_work[df_work[\"label\"] == \"Unknown\"][\"cluster\"]\n",
    "    .value_counts()\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "len(unknown_clusters), unknown_clusters[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6cd0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 ‚Äî Prepare TF-IDF keywords per cluster\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "tfidf = vectorizer.fit_transform(df_work[\"doc\"])\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92a53a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 ‚Äî Function: Get top keywords for a cluster\n",
    "\n",
    "def top_terms_for_cluster(cluster_id, n=10):\n",
    "    idx = df_work[\"cluster\"] == cluster_id\n",
    "    cluster_tfidf = tfidf[idx].mean(axis=0)\n",
    "    scores = np.asarray(cluster_tfidf).flatten()\n",
    "    top_idx = scores.argsort()[::-1][:n]\n",
    "    return terms[top_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9c916bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 ‚Äî Function: Sample example reviews\n",
    "\n",
    "def sample_reviews(cluster_id, n=3):\n",
    "    return (\n",
    "        df_work[df_work[\"cluster\"] == cluster_id][\"doc\"]\n",
    "        .sample(n=min(n, sum(df_work[\"cluster\"] == cluster_id)), random_state=42)\n",
    "        .tolist()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc15f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 ‚Äî Auto-label generator (rule-based)\n",
    "\n",
    "def suggest_label(keywords):\n",
    "    keywords = \" \".join(keywords)\n",
    "\n",
    "    if any(k in keywords for k in [\"size\", \"fit\", \"small\", \"large\", \"tight\", \"wide\"]):\n",
    "        return \"Fit & Sizing Issues\"\n",
    "\n",
    "    if any(k in keywords for k in [\"quality\", \"cheap\", \"broke\", \"durable\", \"poor\"]):\n",
    "        return \"Quality & Durability\"\n",
    "\n",
    "    if any(k in keywords for k in [\"comfortable\", \"comfort\", \"wear\", \"light\"]):\n",
    "        return \"Comfort & Wearability\"\n",
    "\n",
    "    if any(k in keywords for k in [\"fake\", \"authentic\", \"real\", \"counterfeit\"]):\n",
    "        return \"Authenticity Issues\"\n",
    "\n",
    "    if any(k in keywords for k in [\"price\", \"value\", \"worth\"]):\n",
    "        return \"Price & Value\"\n",
    "\n",
    "    if any(k in keywords for k in [\"love\", \"great\", \"perfect\", \"recommend\"]):\n",
    "        return \"Positive Satisfaction\"\n",
    "\n",
    "    return \"Miscellaneous / Other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23fc9f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, 'Fit & Sizing Issues'),\n",
       " (9, 'Miscellaneous / Other'),\n",
       " (3, 'Quality & Durability'),\n",
       " (37, 'Fit & Sizing Issues'),\n",
       " (50, 'Quality & Durability')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 6 ‚Äî Generate label suggestions for Unknown clusters\n",
    "\n",
    "def top_terms_for_cluster(cluster_id, n=10):\n",
    "    idx = (df_work[\"cluster\"] == cluster_id).values  # üî• convert to NumPy\n",
    "    cluster_tfidf = tfidf[idx].mean(axis=0)\n",
    "    scores = np.asarray(cluster_tfidf).flatten()\n",
    "    top_idx = scores.argsort()[::-1][:n]\n",
    "    return terms[top_idx]\n",
    "\n",
    "auto_labels = {}\n",
    "\n",
    "for cid in unknown_clusters:\n",
    "    keywords = top_terms_for_cluster(cid, n=12)\n",
    "    label = suggest_label(keywords)\n",
    "    auto_labels[cid] = label\n",
    "\n",
    "list(auto_labels.items())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7 ‚Äî Review suggestions (CRITICAL STEP)\n",
    "\n",
    "for cid, label in list(auto_labels.items())[:10]:\n",
    "    print(f\"\\n=== Cluster {cid} ‚Üí Suggested: {label} ===\")\n",
    "    print(\"Top terms:\", top_terms_for_cluster(cid))\n",
    "    for r in sample_reviews(cid):\n",
    "        print(\"-\", r[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a245e69",
   "metadata": {},
   "source": [
    "üß† This is where you judge correctness.\n",
    "\n",
    "Keep the label\n",
    "\n",
    "Edit it\n",
    "\n",
    "Or mark cluster for manual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b848dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_labels = {\n",
    "    -1: \"Other / Mixed / Noise\",\n",
    "    9: \"Sweat Protection / Undershirt Performance\",\n",
    "    3: \"Shoe Trees / Sizing & Quality\",\n",
    "    37: \"Shoes / Run Small / Size Accuracy\",\n",
    "    50: \"Socks / Positive Quality & Comfort\",\n",
    "    51: \"Socks / Value, Warmth & Wool Quality\",\n",
    "    12: \"Comfort & Cushioning (Positive)\",\n",
    "    4: \"Generic Positive Reviews\",\n",
    "    48: \"Warmth & Softness (Cold Weather Wear)\",\n",
    "    33: \"Socks / Durability Failures (Holes)\"\n",
    "}\n",
    "\n",
    "# 1Ô∏è‚É£ Apply manual refined labels first\n",
    "df_work['label'] = df_work['cluster'].map(refined_labels).fillna(df_work['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4534230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8 ‚Äî Fill in the remaining Unknowns with auto_labels\n",
    "\n",
    "for cid, label in auto_labels.items():\n",
    "    df_work.loc[\n",
    "        (df_work[\"cluster\"] == cid) & (df_work[\"label\"] == \"Unknown\"),\n",
    "        \"label\"\n",
    "    ] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3eee32f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Other / Mixed / Noise                        918\n",
       "Fit & Sizing Issues                          379\n",
       "Positive / Satisfaction / Quality            215\n",
       "Comfort & Wearability                        159\n",
       "Work / Durability / Fit                      155\n",
       "Quality & Durability                         103\n",
       "Miscellaneous / Other                         95\n",
       "Fit / Authenticity / Defects                  86\n",
       "Socks / Fit & Quality                         76\n",
       "Shoes / Durability & Quality                  75\n",
       "Shoes / Fit & Width Issues                    73\n",
       "Clothing / Fit & Quality                      68\n",
       "Positive Satisfaction                         64\n",
       "Shoes / Comfort & Satisfaction                58\n",
       "Socks / Fit & Comfort                         56\n",
       "Sweat Protection / Undershirt Performance     56\n",
       "Shoe Trees / Sizing & Quality                 54\n",
       "Shoes / Run Small / Size Accuracy             52\n",
       "Comfort & Cushioning (Positive)               42\n",
       "Socks / Value, Warmth & Wool Quality          42\n",
       "Socks / Positive Quality & Comfort            42\n",
       "Warmth & Softness (Cold Weather Wear)         39\n",
       "Generic Positive Reviews                      39\n",
       "Socks / Durability Failures (Holes)           38\n",
       "Authenticity Issues                           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 9 ‚Äî Check remaining Unknowns\n",
    "# You should now have far fewer \"Unknown\"\n",
    "\n",
    "\n",
    "df_work[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87c3b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10 ‚Äî Save final labeled dataset\n",
    "\n",
    "df_work.to_csv(\"amazon_reviews_with_final_labels.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
